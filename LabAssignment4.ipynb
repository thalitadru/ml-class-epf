{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LabAssignment4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPiqi6U95tNiLEO/nZVP4Bm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thalitadru/ml-class-epf/blob/main/LabAssignment4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOJg0qAE0-Ql"
      },
      "source": [
        "# Exercices\n",
        "You have 4 exercises in this lab assignment. Only the last two should be submitted on Moodle, the other 2 are optional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPLM2m6Ph9NR"
      },
      "source": [
        "*Credits:* Exercises from A. Géron \"Hands-on ML with scikit-learn, keras and tensorflow.\", 2nd edition 2019, O'Reilly Media."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h13UMb-Dh9rl"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import scipy as sp\n",
        "from scipy import stats\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSeZPqw_Qv0I"
      },
      "source": [
        "## (Optional) Train and fine-tune a decision tree\n",
        "Train and fine-tune a Decision Tree for the moons dataset by following these steps:  \n",
        "  1. Use `make_moons(n_samples=10000, noise=0.4)` to generate a moons dataset.   \n",
        "  1. Use `train_test_split()` to split the dataset into a training set and a test set.\n",
        "  1. Use grid search with cross-validation (with the help of the `GridSearchCV` class) to find good hyperparameter values for a `DecisionTreeClassifier`. Hint: try various values for `max_leaf_nodes`.\n",
        "  1. Train it on the full training set using these hyperparameters, and measure your model's performance on the test set. You should get roughly 85% to 87% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4wJJZPrRCzo"
      },
      "source": [
        "## (Optional) Grow your own random forest\n",
        "Grow a forest by following these steps:  \n",
        "  \n",
        "  1. Continuing the previous exercise, generate 1,000 subsets of the training set, each containing 100 instances selected randomly. *Hint*: you can use ScikitLearn’s `ShuffleSplit` class for this.  \n",
        "  1. Train one Decision Tree on each subset, using the best hyperparameter values found in the previous exercise. Evaluate these 1,000 Decision Trees on the test set. Since they were trained on smaller sets, these Decision Trees will likely perform worse than the first Decision Tree, achieving only about 80% accuracy.  \n",
        "  1. Now comes the magic. For each test set instance, generate the predictions of the 1,000 Decision Trees, and keep only the most frequent prediction (you can use SciPy’s `mode()` function for this). This approach gives you majority-vote predictions over the test set.  \n",
        "  1. Evaluate these predictions on the test set: you should obtain a slightly higher accuracy than your first model (about 0.5 to 1.5% higher).   \n",
        "  1. Congratulations, you have trained a Random Forest classifier!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXmHwioGiHMB"
      },
      "source": [
        "## Voting Classifier on MNIST\n",
        "\n",
        "1. Load the MNIST data and split it into a training set, a validation set, and a test set (e.g., use 50,000 instances for training, 10,000 for validation, and 10,000 for testing). \n",
        "\n",
        "1. Then train various classifiers, such as a Random Forest classifier, an Extra-Trees classifier, and an SVM classifier. \n",
        "\n",
        "1. Next, try to combine them into an ensemble that outperforms each individual classifier on the validation set, using soft or hard voting.\n",
        "\n",
        "1. Once you have found one, try it on the test set. \n",
        " \n",
        "1. How much better does it perform compared to the individual classifiers?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8-72W2ViHMQ"
      },
      "source": [
        "## Stacking Ensemble on MNIST\n",
        "1. Run the individual classifiers from the previous exercise to make predictions on the validation set, and create a new training set with the resulting predictions: each training instance is a vector containing the set of predictions from all your classifiers for an image, and the target is the image’s class.\n",
        "1. Train a classifier on this new training set. \n",
        "1. Congratulations, you have just trained a blender, and together with the classifiers it forms a stacking ensemble! \n",
        "1. Now evaluate the ensemble on the test set. \n",
        "1. For each image in the test set, make predictions with all your classifiers, then feed the predictions to the blender to get the ensemble’s predictions.\n",
        "1. How does it compare to the voting classifier you trained earlier?"
      ]
    }
  ]
}