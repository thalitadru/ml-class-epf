{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/thalitadru/ml-class-epf/blob/main/LabAssignmentCNNFlowers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification with a CNN on the Flowers dataset\n",
    "\n",
    "*Credits*: This notebook is based on [Tensorflow tutorial on image classification](https://www.tensorflow.org/tutorials/images/classification) (content licensed under the [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/), and code samples are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:23:23.464306Z",
     "iopub.status.busy": "2022-08-12T01:23:23.463686Z",
     "iopub.status.idle": "2022-08-12T01:23:26.257466Z",
     "shell.execute_reply": "2022-08-12T01:23:26.256487Z"
    },
    "id": "L1WtoaOHVrVh"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import PIL\n",
    "\n",
    "import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(1)\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: use the following seed throughout this noitebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZZI6lNkVrVm"
   },
   "source": [
    "## Download and explore the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPHx8-t-VrVo"
   },
   "source": [
    "This tutorial uses a dataset of about 3,700 photos of flowers. The dataset contains five sub-directories, one per class:\n",
    "\n",
    "```\n",
    "flower_photo/\n",
    "  daisy/\n",
    "  dandelion/\n",
    "  roses/\n",
    "  sunflowers/\n",
    "  tulips/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:23:26.263115Z",
     "iopub.status.busy": "2022-08-12T01:23:26.262673Z",
     "iopub.status.idle": "2022-08-12T01:23:26.267555Z",
     "shell.execute_reply": "2022-08-12T01:23:26.266819Z"
    },
    "id": "57CcilYSG0zv"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpmywIlsVrVx"
   },
   "source": [
    "After downloading, you should now have a copy of the dataset available. There are 3,670 total images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:23:26.271379Z",
     "iopub.status.busy": "2022-08-12T01:23:26.271128Z",
     "iopub.status.idle": "2022-08-12T01:23:26.287472Z",
     "shell.execute_reply": "2022-08-12T01:23:26.286680Z"
    },
    "id": "SbtTDYhOHZb6"
   },
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can open an image as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:23:26.291704Z",
     "iopub.status.busy": "2022-08-12T01:23:26.291130Z",
     "iopub.status.idle": "2022-08-12T01:23:26.322561Z",
     "shell.execute_reply": "2022-08-12T01:23:26.321767Z"
    },
    "id": "N1loMlbYHeiJ"
   },
   "outputs": [],
   "source": [
    "# List files in a directory\n",
    "roses = list(data_dir.glob('roses/*'))\n",
    "# Read image with PIL\n",
    "PIL.Image.open(str(roses[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO Open some other images\n",
    "Open another rose image and one image from another class of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIjgz7_JIo_m"
   },
   "source": [
    "## Load data using a Keras utility\n",
    "\n",
    "We will load these images off disk using the helpful [`tf.keras.utils.image_dataset_from_directory`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory) utility. \n",
    "This will take you from a directory of images on disk to a [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) in just a couple lines of code. \n",
    "You can learn more about loading images into Tensorflow in the following tutorial: [Load and preprocess images](../load_data/images.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anqiK_AGI086"
   },
   "source": [
    "We need to tell the loading function some paramaters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:23:26.413793Z",
     "iopub.status.busy": "2022-08-12T01:23:26.413533Z",
     "iopub.status.idle": "2022-08-12T01:23:26.417347Z",
     "shell.execute_reply": "2022-08-12T01:23:26.416614Z"
    },
    "id": "H74l2DoDI2XD"
   },
   "outputs": [],
   "source": [
    "# Number of images in a batch\n",
    "batch_size = 32\n",
    "# The desired image size\n",
    "# Images not mathcing it will be resized accordingly\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFBhRrrEI49z"
   },
   "source": [
    "We can also tell the loader to separate part of the images for a validation set via the argument `validation_split`, and select the split (training or validation) with `subset`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### TODO complete the code\n",
    "\n",
    "- Complete the code bellow in order to used the parameters defined above. \n",
    "- Use 80% of the images for training and 20% for validation.\n",
    "- Set the seed for reproducible data shuffling\n",
    "\n",
    "**Note**: Since this datset is quite small, we will not separate a test split. When doing this, we would need to build a test set with new flower images in order to have an unbiased estimate our production performance.\n",
    "\n",
    "Check the documentation if needed:\n",
    "[`tf.keras.utils.image_dataset_from_directory`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:23:26.421338Z",
     "iopub.status.busy": "2022-08-12T01:23:26.421075Z",
     "iopub.status.idle": "2022-08-12T01:23:29.746971Z",
     "shell.execute_reply": "2022-08-12T01:23:29.746063Z"
    },
    "id": "fIR0kRZiI_AT"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    ...\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:23:29.750896Z",
     "iopub.status.busy": "2022-08-12T01:23:29.750600Z",
     "iopub.status.idle": "2022-08-12T01:23:29.927383Z",
     "shell.execute_reply": "2022-08-12T01:23:29.926562Z"
    },
    "id": "iscU3UoVJBXj"
   },
   "outputs": [],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    ...\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Dataset object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets can be iterated through in `for`  loops. The dataset constructed by Keras yields a tuple object with two elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in train_ds:\n",
    "    print(\"type:\", type(sample), \"lenght:\", len(sample))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first element is a batch of images, and the second is a batch of the associated labels (as integers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in train_ds:\n",
    "    print(image.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLQULyAvJC3X"
   },
   "source": [
    "Keras also takes into account the names of the subfolders to infer which are the text labels associated to each class. \n",
    "You can find them in the `class_names` attribute on these datasets. These correspond to the directory names in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:23:29.931311Z",
     "iopub.status.busy": "2022-08-12T01:23:29.931021Z",
     "iopub.status.idle": "2022-08-12T01:23:29.935382Z",
     "shell.execute_reply": "2022-08-12T01:23:29.934628Z"
    },
    "id": "ZHAxkHX5JD3k"
   },
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uoVvxSLJW9m"
   },
   "source": [
    "### Visualize the dataset\n",
    "\n",
    "Here are the first nine images from the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:23:29.939276Z",
     "iopub.status.busy": "2022-08-12T01:23:29.939025Z",
     "iopub.status.idle": "2022-08-12T01:23:30.593412Z",
     "shell.execute_reply": "2022-08-12T01:23:30.592456Z"
    },
    "id": "wBmEA9c0JYes"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5M6BXtXFJdW0"
   },
   "source": [
    "You will pass these datasets to the Keras `Model.fit` method for training later in this tutorial. If you like, you can also manually iterate over the dataset and retrieve batches of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:23:30.603787Z",
     "iopub.status.busy": "2022-08-12T01:23:30.603515Z",
     "iopub.status.idle": "2022-08-12T01:23:30.675685Z",
     "shell.execute_reply": "2022-08-12T01:23:30.674813Z"
    },
    "id": "2-MfMoenJi8s"
   },
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(\"image batch shape: \", image_batch.shape)\n",
    "  print(\"label batch shape: \", labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wj4FrKxxJkoW"
   },
   "source": [
    "The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images.\n",
    "\n",
    "You can call `.numpy()` on the `image_batch` and `labels_batch` tensors to convert them to a `numpy.ndarray`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Dr0at41KcAU"
   },
   "source": [
    "## Configure the dataset for performance\n",
    "\n",
    "Make sure to use buffered prefetching, so you can yield data from disk without having I/O become blocking. These are two important methods you should use when loading data:\n",
    "\n",
    "- `Dataset.cache` keeps the images in memory after they're loaded off disk during the first epoch. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.\n",
    "- `Dataset.prefetch` overlaps data preprocessing and model execution while training.\n",
    "\n",
    "Interested readers can learn more about both methods, as well as how to cache data to disk in the *Prefetching* section of the [Better performance with the tf.data API](../../guide/data_performance.ipynb) guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:23:30.680785Z",
     "iopub.status.busy": "2022-08-12T01:23:30.680106Z",
     "iopub.status.idle": "2022-08-12T01:23:30.692044Z",
     "shell.execute_reply": "2022-08-12T01:23:30.691278Z"
    },
    "id": "nOjJSm7DKoZA"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GUnmPF4JvEf"
   },
   "source": [
    "## Normalize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e56VXHMWJxYT"
   },
   "source": [
    "The RGB channel values are in the `[0, 255]` range. This is not ideal for a neural network; in general you should seek to make your input values small.\n",
    "\n",
    "Here, you will normalize values to be in the `[0, 1]` range by using `tf.keras.layers.Rescaling`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:23:30.696496Z",
     "iopub.status.busy": "2022-08-12T01:23:30.696258Z",
     "iopub.status.idle": "2022-08-12T01:23:30.701842Z",
     "shell.execute_reply": "2022-08-12T01:23:30.701107Z"
    },
    "id": "PEYxo2CTJvY9"
   },
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bl4RmanbJ4g0"
   },
   "source": [
    "There are two ways to use this layer. You can apply it to the dataset by calling `Dataset.map`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:23:30.705718Z",
     "iopub.status.busy": "2022-08-12T01:23:30.705472Z",
     "iopub.status.idle": "2022-08-12T01:23:31.226873Z",
     "shell.execute_reply": "2022-08-12T01:23:31.225842Z"
    },
    "id": "X9o9ESaJJ502"
   },
   "outputs": [],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWEOmRSBJ9J8"
   },
   "source": [
    "Or, you can include the layer inside your model definition, which can simplify deployment. Use the second approach here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsRk1xCwKZR4"
   },
   "source": [
    "**Note**: You previously resized images using the `image_size` argument of `tf.keras.utils.image_dataset_from_directory`. If you want to include the resizing logic in your model as well, you can use the `tf.keras.layers.Resizing` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcUTyDOPKucd"
   },
   "source": [
    "## A basic CNN model\n",
    "\n",
    "### TODO Create the model\n",
    "\n",
    "Using a Keras [Sequential](https://www.tensorflow.org/guide/keras/sequential_model) model, you will create a small convolutional network.\n",
    "The model consists of:\n",
    "- a preprocessing layer that rescales values by 1/255. since this is the first layer in the model, don't forget to pass it the parameter `input_shape`.\n",
    "- three convolution layers ([`tf.keras.layers.Conv2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)) \n",
    "with a max pooling layer ([`tf.keras.layers.MaxPooling2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D)) after each of them;\n",
    "    - Use `padding='same'` for the convolutions\n",
    "    - Use ReLU activations and 3x3 kernels\n",
    "    - Use an increasing number of channels: 16, 32, and 64, respectively\n",
    "- a fully-connected layer (`tf.keras.layers.Dense`) with 128 units, with ReLU activation functions;\n",
    "- finally an output layer with one neuron per class. \n",
    "    - Do not use the softmax activation here, as we will be computing the cross entropy loss directly from the logits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:23:31.232248Z",
     "iopub.status.busy": "2022-08-12T01:23:31.231977Z",
     "iopub.status.idle": "2022-08-12T01:23:31.340048Z",
     "shell.execute_reply": "2022-08-12T01:23:31.339187Z"
    },
    "id": "QR6argA1K074"
   },
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# TODO complete the list of layers\n",
    "model = Sequential([\n",
    "    # include preprocessing layer, along with the input shape\n",
    "    ...\n",
    "    # TODO complete the Conv2D calls\n",
    "    layers.Conv2D(...),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(...),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(...),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    # TODO include the final Dense layers\n",
    "    ...\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaKFzz72Lqpg"
   },
   "source": [
    "### TODO Compile the model\n",
    "\n",
    "Complete the call in order to:\n",
    "- use Adam optimizer\n",
    "- use loss computed from logits\n",
    "- include accuracy in the monitored metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:23:31.344202Z",
     "iopub.status.busy": "2022-08-12T01:23:31.343913Z",
     "iopub.status.idle": "2022-08-12T01:23:31.357402Z",
     "shell.execute_reply": "2022-08-12T01:23:31.356547Z"
    },
    "id": "jloGNS1MLx3A"
   },
   "outputs": [],
   "source": [
    "# TODO your code here\n",
    "model.compile(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring callbacks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use some callbacks to monitor the evolution of our training:\n",
    "- TensorBoard\n",
    "- ModelCheckpoint\n",
    "- BackupAndRestore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deirectory in which modelcheckpoints and logs are saved\n",
    "LOG_DIR = 'flowers_logs'\n",
    "\n",
    "def best_model_path(model_name):\n",
    "    base_dir  = os.path.join(LOG_DIR, model_name)\n",
    "    return os.path.join(base_dir, 'best_val_accuracy.ckpt')\n",
    "\n",
    "def callback_list(model_name):\n",
    "    base_dir  = os.path.join(LOG_DIR, model_name)\n",
    "    tb_cb = tf.keras.callbacks.TensorBoard(base_dir)\n",
    "    ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "         best_model_path(model_name),\n",
    "         monitor='val_accuracy',\n",
    "         mode='max', \n",
    "         verbose=0,\n",
    "         save_best_only=True)\n",
    "    backup_dir = os.path.join(base_dir, 'backup_checkpoint')\n",
    "    bkp = tf.keras.callbacks.BackupAndRestore(\n",
    "        backup_dir)\n",
    "    return [tb_cb, ckpt, bkp]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiYHcbvaL9H-"
   },
   "source": [
    "### TODO Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j30F69T4sIVN"
   },
   "source": [
    "Train the model for (up to) 10 epochs with the Keras `Model.fit` method. Complete the function call bellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:23:31.397663Z",
     "iopub.status.busy": "2022-08-12T01:23:31.397411Z",
     "iopub.status.idle": "2022-08-12T01:23:47.039629Z",
     "shell.execute_reply": "2022-08-12T01:23:47.038769Z"
    },
    "id": "5fWToCqYMErH"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'base_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "# this dictionnary will stock the logs for each model trained throughout this notebook\n",
    "logs = {}\n",
    "\n",
    "# TODO complete the fit call\n",
    "logs[MODEL_NAME] = model.fit(\n",
    "    ...\n",
    "    callbacks=callback_list(MODEL_NAME)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixsz9XFfMxcu"
   },
   "source": [
    "## Results\n",
    "\n",
    "TODO Launch a Tensorboard session here to monitor your learning curves. Pay attention to the ` LOG_DIR`  used in the logging calbacks, the same directory should be passed in the tensorboard call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Load the tensorboard extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO call tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You should see that training accuracy is increasing linearly over time, whereas validation accuracy stalls around 60% in the training process. Also, the difference in accuracy between training and validation accuracy is noticeable — a sign of [overfitting](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit).\n",
    "\n",
    "When there are a small number of training examples, the model sometimes learns from noises or unwanted details from training examples—to an extent that it negatively impacts the performance of the model on new examples. This phenomenon is known as overfitting. It means that the model will have a difficult time generalizing on a new dataset.\n",
    "\n",
    "There are multiple ways to fight overfitting in deep networks. In the next exercises, you'll use *data augmentation* and add *dropout* to your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxYwix81M2YO"
   },
   "source": [
    "Overfitting generally occurs when there are a small number of training examples.\n",
    " [Data augmentation](https://www.tensorflow.org/tutorials/images/data_augmentation) \n",
    " takes the approach of generating additional training data from your existing examples\n",
    "  by augmenting them using random transformations that yield believable-looking images. \n",
    " This helps expose the model to more aspects of the data and generalize better.\n",
    "\n",
    "You will implement data augmentation using the following Keras preprocessing layers:\n",
    " [`tf.keras.layers.RandomFlip`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomFlip), \n",
    " [`tf.keras.layers.RandomRotation`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomRotation),\n",
    "  and [`tf.keras.layers.RandomZoom`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomZoom). \n",
    "These can be included inside your model like other layers, and run on the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO Augmentation parameters\n",
    "Prepare an augmentation pipline that applies the following transforms:\n",
    "- Randomly flips the image horizontally\n",
    "- Randomly rotates the images of $\\pm$ 10% (of a full turn)\n",
    "- Randomly zooms the image out by 10%\n",
    "\n",
    "Don't forget to set the seed for these random transformations to get reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:23:47.307692Z",
     "iopub.status.busy": "2022-08-12T01:23:47.307455Z",
     "iopub.status.idle": "2022-08-12T01:23:47.516804Z",
     "shell.execute_reply": "2022-08-12T01:23:47.516006Z"
    },
    "id": "9J80BAbIMs21"
   },
   "outputs": [],
   "source": [
    "# TODO complete the code bellow\n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(...),\n",
    "    layers.RandomRotation(...),\n",
    "    layers.RandomZoom(...),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing augmented data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PN4k1dK3S6eV"
   },
   "source": [
    "You can visualize a few augmented examples by applying data augmentation to the same image several times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:23:47.521145Z",
     "iopub.status.busy": "2022-08-12T01:23:47.520859Z",
     "iopub.status.idle": "2022-08-12T01:23:50.081287Z",
     "shell.execute_reply": "2022-08-12T01:23:50.080421Z"
    },
    "id": "7Z90k539S838"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    augmented_images = data_augmentation(images)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO Create new model and train it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsjXCBLYYNs5"
   },
   "source": [
    "You add data augmentation to your model and train it again. To do so, note that `Sequential` can work with a sequence of layers and/or models. You can create a new `Sequential` model combining the ` data_augmentation` pipeline and the previously declared `model`. \n",
    "\n",
    "Is the overfitting reduced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'model_augment'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_augment = Sequential([\n",
    "    # TODO complete the list of layers/models\n",
    "    ...\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO your code here\n",
    "model_augment.compile(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO your code here\n",
    "EPOCHS = 10\n",
    "\n",
    "logs[MODEL_NAME] = model_augment.fit(\n",
    "    ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeD3bXepYKXs"
   },
   "source": [
    "## Exercise: Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Another technique to reduce overfitting is to introduce [dropout](https://developers.google.com/machine-learning/glossary#dropout_regularization) regularization to the network.\n",
    "\n",
    "When you apply dropout to a layer, it randomly drops out (by setting the activation to zero) a number of output units from the layer during the training process. Dropout takes a fractional number as its input value, in the form such as 0.1, 0.2, 0.4, etc. This means dropping out 10%, 20% or 40% of the output units randomly from the applied layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### TODO Create new model and train it\n",
    "- Create a new neural network with a `tf.keras.layers.Dropout` layer between the convolutionl layers and the final dense layers. Use a rate of 0.2.\n",
    "- Train it again for the same number of epochs. \n",
    "- Is the overfitting reduced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'model_augment_dropout'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:23:50.090306Z",
     "iopub.status.busy": "2022-08-12T01:23:50.090041Z",
     "iopub.status.idle": "2022-08-12T01:23:50.341455Z",
     "shell.execute_reply": "2022-08-12T01:23:50.340521Z"
    },
    "id": "2Zeg8zsqXCsm"
   },
   "outputs": [],
   "source": [
    "model_augment_dropout = Sequential([\n",
    "    # TODO complet with the sequence of layers/models\n",
    "    ...\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO your code here\n",
    "model_augment_dropout.compile(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training model with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "# TODO your code here\n",
    "logs[MODEL_NAME] = model_augment_dropout.fit(\n",
    "  ...\n",
    "  callbacks=callback_list(MODEL_NAME)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results summary\n",
    "Here we gather the logs of all 3 models and plot them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each log, get history\n",
    "for k, v in logs.items():\n",
    "    logs[k] = v.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a flatened dictionnary out of the nested one\n",
    "flat_dict = {}\n",
    "for model, history in logs.items():\n",
    "    for metric, curve in history.items():\n",
    "        flat_dict[(metric, model)] = curve\n",
    "# use it to create a multi-index column dataframe\n",
    "logs_df = pd.DataFrame(flat_dict)\n",
    "logs_df.columns.set_names(['metric', 'model'])\n",
    "logs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots\n",
    "fig, (ax0,ax1) = plt.subplots(2, 1, sharex=True, figsize=(16,8))\n",
    "logs_df[['accuracy','val_accuracy']].plot(ax=ax0)\n",
    "logs_df[['loss','val_loss']].plot(ax=ax1)\n",
    "ax0.set_xlabel('epochs')\n",
    "ax1.set_xlabel('epochs')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you conclude about the three models tested? Which one seems the best candidate for further developments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra: transfer learning\n",
    "\n",
    "Following the transfer learning tutorial, load a pretrained model from `tf.keras.applications` and pply it to the flowers data:\n",
    "- First, freeze the pre-trained model and train a new classification head on top of it. How well does it perform?\n",
    "- Then, un-freeze the pre-trained model and fine-une it using a lower learning rate. How well does it perform?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf-latest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15d9c75a48019379bcf66ddeaa4ae8c0cf85a12b8151e3313e625976ab5234ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
