{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasUsingPreTrainedModels.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNcJLZBvzSoNY/ibeWGeI95"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dky6s1aNj2JB"
      },
      "source": [
        "# Using pre-trained models from keras.applications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--j6zFZjYCDZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQw585hfYeZI"
      },
      "source": [
        "## Pick a model:\n",
        "\n",
        "You can see all models available in `keras.applications` [on this page](https://keras.io/api/applications/#available-models).\n",
        "\n",
        "Try other models such as:\n",
        "- InceptionV3\n",
        "- MobileNetV2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNGIstgPYF6_"
      },
      "source": [
        "from tensorflow.keras.applications import resnet50\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "model = ResNet50(weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmHnj1lBi8_G"
      },
      "source": [
        "You can use `model.summary` and `keras.utils.plot_model` to help you visualize the architecture of the model you are using.\n",
        "\n",
        "Note how many trainable parameters the model has. Compare this quantity between models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbtLY2p5f-Cv"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYJf9Cdli95u"
      },
      "source": [
        "keras.utils.plot_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lysG7ayDYYo0"
      },
      "source": [
        "## Donwload an image to be classified\n",
        "If you are running this notebook locally (and not in colab), change the `cache_subdir` parameter to change where the image is downloaded. If you leave it empty, it defaults to `~/.keras`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--XhBlo2ZAGn"
      },
      "source": [
        "img_path = 'elephant.jpg'\n",
        "img_url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/African_Bush_Elephant.jpg/1200px-African_Bush_Elephant.jpg'\n",
        "keras.utils.get_file(img_path, origin=img_url, cache_subdir='/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PanpQxv9YFoe"
      },
      "source": [
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "plt.imshow(img)\n",
        "plt.axis('off');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hgx6z9hf22P"
      },
      "source": [
        "## Preprocessing image\n",
        "The image needs to have 4 dimensions. The first one correspond to the array of images submitted to the model (the batch). The second and third correspond to the height and width of the image, while the third corresponds to the color channels (red, green and blue).\n",
        "\n",
        "**Attention** In some models/libraries the convention is to have the channels dimension first, before height and width. You can also set keras to follow this convention if needed.\n",
        "\n",
        "Moreover, each model was trained expecting a specific input size, as well as specific pixel normalizations applied to the image. The function `preprocess_input` takes all into account and preprocess the image accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXzdojpFYJ-J"
      },
      "source": [
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = resnet50.preprocess_input(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXqTEC35f7Jq"
      },
      "source": [
        "## Computing predictions\n",
        "You can use `model.predict` to compute predictions for an array X as you would do to a custom created model. Each model may have associated functions to decode its output into probability predictions: it is the case for ResNet-50 with the `resnet50.decode_predictions`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2di5ItgpYLZA"
      },
      "source": [
        "preds = model.predict(x)\n",
        "# decode the results into a list of tuples (class, description, probability)\n",
        "# (one such list for each sample in the batch)\n",
        "print('Predicted:', resnet50.decode_predictions(preds, top=3)[0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}